{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f95b6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a9fba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class I_ELM():\n",
    "    \"\"\" Constructor to initialize node\"\"\"\n",
    "    def __init__(self, no_input_nodes, max_no_hidden_nodes, no_output_nodes,\n",
    "        activation_function='sigmoid', loss_function='mean_squared_error'):\n",
    "\n",
    "        #self.name = name\n",
    "        self.no_input_nodes = no_input_nodes\n",
    "        self.no_hidden_nodes = 1\n",
    "        self.no_output_nodes = no_output_nodes\n",
    "\n",
    "        # initialize weights between  hidden layer and Output Layer\n",
    "        self.beta = np.random.uniform(-1.,1.,size=(self.no_hidden_nodes, self.no_output_nodes))\n",
    "        # initialize weights between Input Layer and hidden layer\n",
    "        self.alpha = np.random.uniform(-1.,1.,size=(self.no_input_nodes, self.no_hidden_nodes))\n",
    "        #Initialize Biases\n",
    "        self.bias = np.zeros(shape=(self.no_hidden_nodes,))\n",
    "        # set an activation function\n",
    "        self.activation_function = activation_function\n",
    "        # set a loss function\n",
    "        self.loss_function = loss_function\n",
    "    \n",
    "    def mean_squared_error(self,Y_True, Y_Pred):\n",
    "        return 0.5 * np.mean((Y_True - Y_Pred)**2)\n",
    "\n",
    "    def mean_absolute_error(self, Y_True, Y_Pred):\n",
    "        return np.mean(np.abs(Y_True - Y_Pred))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return list(self(X))\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        h = self.sigmoid(X.dot(self.alpha) + self.bias)\n",
    "        return h.dot(self.beta)\n",
    "\n",
    "    def evaluate(self, X, Y_true, metrics=['loss']):\n",
    "        Y_pred = self.predict(X)\n",
    "        Y_true = Y_true\n",
    "        Y_pred_argmax = np.argmax(Y_pred, axis=-1)\n",
    "        Y_true_argmax = np.argmax(Y_true, axis=-1)\n",
    "        ret = []\n",
    "        for m in metrics:\n",
    "            if m == 'loss':\n",
    "                loss = self.mean_squared_error(Y_true, Y_pred)\n",
    "                ret.append(loss)\n",
    "            elif m == 'accuracy':\n",
    "                acc = np.sum(Y_pred_argmax == Y_true_argmax) / len(Y_true)\n",
    "                ret.append(acc)\n",
    "            else:\n",
    "                raise ValueError('an unknown evaluation indicator \\'%s\\'.' % m)\n",
    "        if len(ret) == 1:\n",
    "            ret = ret[0]\n",
    "        elif len(ret) == 0:\n",
    "            ret = None\n",
    "        return ret\n",
    "\n",
    "    def fit(self, X, Y_true,Lmax,error):\n",
    "        self.beta = np.random.uniform(-1.,1.,size=(1, self.no_output_nodes))\n",
    "        self.alpha = np.random.uniform(-1.,1.,size=(self.no_input_nodes, 1))\n",
    "#         print(self.beta.shape,self.alpha.shape)\n",
    "        H = self.sigmoid(X.dot(self.alpha))\n",
    "        # compute a pseudoinverse of H\n",
    "        H_pinv = np.linalg.pinv(H)\n",
    "        # update beta\n",
    "        self.beta = H_pinv.dot(Y_true)\n",
    "\n",
    "        \n",
    "        for i in range(2,Lmax):\n",
    "            beta_random = np.random.uniform(-1.,1.,size=(1, self.no_output_nodes))\n",
    "            alpha_random = np.random.uniform(-1.,1.,size=(self.no_input_nodes, 1))\n",
    "            self.alpha=np.hstack([self.alpha,alpha_random])\n",
    "#             print(self.beta.shape,beta_random.shape)\n",
    "            self.beta = np.vstack([self.beta,beta_random])\n",
    "            H = self.sigmoid(X.dot(self.alpha))\n",
    "            # compute a pseudoinverse of H\n",
    "            H_pinv = np.linalg.pinv(H)\n",
    "            # update beta\n",
    "            self.beta = H_pinv.dot(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fdd742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train=np.load(\"X_Train.npy\")\n",
    "X_Test=np.load(\"X_Test.npy\")\n",
    "\n",
    "Y_Train = np.load(\"Y_Train.npy\")\n",
    "Y_Test = np.load(\"Y_Test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22886069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.2       , 0.62352943, 0.99215686,\n",
       "       0.62352943, 0.19607843, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1882353 ,\n",
       "       0.93333334, 0.9882353 , 0.9882353 , 0.9882353 , 0.92941177,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.21176471, 0.8901961 , 0.99215686, 0.9882353 ,\n",
       "       0.9372549 , 0.9137255 , 0.9882353 , 0.22352941, 0.02352941,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03921569, 0.23529412, 0.8784314 ,\n",
       "       0.9882353 , 0.99215686, 0.9882353 , 0.7921569 , 0.32941177,\n",
       "       0.9882353 , 0.99215686, 0.47843137, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.6392157 , 0.9882353 , 0.9882353 , 0.9882353 , 0.99215686,\n",
       "       0.9882353 , 0.9882353 , 0.3764706 , 0.7411765 , 0.99215686,\n",
       "       0.654902  , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.2       , 0.93333334, 0.99215686,\n",
       "       0.99215686, 0.74509805, 0.44705883, 0.99215686, 0.89411765,\n",
       "       0.18431373, 0.30980393, 1.        , 0.65882355, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1882353 ,\n",
       "       0.93333334, 0.9882353 , 0.9882353 , 0.7019608 , 0.04705882,\n",
       "       0.29411766, 0.4745098 , 0.08235294, 0.        , 0.        ,\n",
       "       0.99215686, 0.9529412 , 0.19607843, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.14901961, 0.64705884, 0.99215686, 0.9137255 ,\n",
       "       0.8156863 , 0.32941177, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.99215686, 0.9882353 ,\n",
       "       0.64705884, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02745098, 0.69803923,\n",
       "       0.9882353 , 0.9411765 , 0.2784314 , 0.07450981, 0.10980392,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.99215686, 0.9882353 , 0.7647059 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.22352941, 0.9882353 , 0.9882353 , 0.24705882,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.99215686,\n",
       "       0.9882353 , 0.7647059 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.7764706 ,\n",
       "       0.99215686, 0.74509805, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.99215686, 0.76862746,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.29803923, 0.9647059 , 0.9882353 , 0.4392157 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.99215686, 0.9882353 , 0.5803922 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.33333334,\n",
       "       0.9882353 , 0.9019608 , 0.09803922, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02745098, 0.5294118 , 0.99215686, 0.7294118 ,\n",
       "       0.04705882, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.33333334, 0.9882353 , 0.8745098 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02745098, 0.5137255 ,\n",
       "       0.9882353 , 0.88235295, 0.2784314 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.33333334, 0.9882353 , 0.5686275 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.1882353 , 0.64705884, 0.9882353 , 0.6784314 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.3372549 , 0.99215686,\n",
       "       0.88235295, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.44705883, 0.93333334, 0.99215686,\n",
       "       0.63529414, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.33333334, 0.9882353 , 0.9764706 , 0.57254905,\n",
       "       0.1882353 , 0.11372549, 0.33333334, 0.69803923, 0.88235295,\n",
       "       0.99215686, 0.8745098 , 0.654902  , 0.21960784, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.33333334,\n",
       "       0.9882353 , 0.9882353 , 0.9882353 , 0.8980392 , 0.84313726,\n",
       "       0.9882353 , 0.9882353 , 0.9882353 , 0.76862746, 0.50980395,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.10980392, 0.78039217, 0.9882353 ,\n",
       "       0.9882353 , 0.99215686, 0.9882353 , 0.9882353 , 0.9137255 ,\n",
       "       0.5686275 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09803922, 0.5019608 , 0.9882353 , 0.99215686,\n",
       "       0.9882353 , 0.5529412 , 0.14509805, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fff52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "Lmax = 100\n",
    "error = 0.1\n",
    "loss_function = \"mean_squared_error\"  #It can be mean_absolute_error also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45df7139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss in mean square error: 0.024322\n",
      "Training Accuracy: 0.794983\n",
      "Total Time require for Training 296.864780 Seconds\n"
     ]
    }
   ],
   "source": [
    "activation_function = \"sigmoid\"\n",
    "model = I_ELM(\n",
    "        no_input_nodes=28**2,\n",
    "        max_no_hidden_nodes=Lmax,\n",
    "        no_output_nodes=num_classes,\n",
    "        loss_function=loss_function,\n",
    "        activation_function=activation_function,  \n",
    "    )\n",
    "import time\n",
    "i = time.time()\n",
    "model.fit(X_Train, Y_Train,Lmax,error)\n",
    "final = time.time()\n",
    "training_loss, training_acc = model.evaluate(X_Train, Y_Train, metrics=['loss', 'accuracy'])\n",
    "print('Training Loss in mean square error: %f' % training_loss) # loss value\n",
    "print('Training Accuracy: %f' % training_acc)# accuracy\n",
    "print('Total Time require for Training %f Seconds'% (final-i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18121cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss in mean square error: 0.024017\n",
      "Test Accuracy: 0.802200\n",
      "Total Time require for Test 0.449784 Seconds\n"
     ]
    }
   ],
   "source": [
    "i = time.time()\n",
    "test_loss, test_acc = model.evaluate(X_Test, Y_Test, metrics=['loss', 'accuracy'])\n",
    "final = time.time()\n",
    "print('Test Loss in mean square error: %f' % test_loss) # loss value\n",
    "print('Test Accuracy: %f' % test_acc)# accuracy\n",
    "print('Total Time require for Test %f Seconds'% (final-i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b414e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
