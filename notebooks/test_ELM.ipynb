{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELM DPU example: MNIST Classifier\n",
    "-- modified from offical DPU-PYNQ projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq_dpu import DpuOverlay\n",
    "overlay = DpuOverlay(\"dpu.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_model()` method will automatically prepare the `graph`\n",
    "which is used by VART."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.load_model(\"ELM_CNN_kv260.xmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import some libraries as well. The `mnist` package\n",
    "requires some additional headers for URL requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from six.moves import urllib\n",
    "\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load test data\n",
    "\n",
    "The `mnist` package enables the following data for users:\n",
    "\n",
    "* `test_images()`: returns test images stored as a numpy array. \n",
    "Each image is a grayscale 28x28 pixels, representing a digit between 0 and 9.\n",
    "* `test_labels()`: returns a list of the true labels stored as numpy array.\n",
    "\n",
    "\n",
    "There are 2 pre-processing steps we need to do to the test images \n",
    "before we can use it:\n",
    "\n",
    "1. The raw numpy array delivered by `mnist` has a data type of \n",
    "uint8 (data ranges from 0 to 255); we need to normalize the elements to \n",
    "floating-point numbers ranging from 0 to 1.\n",
    "2. The VART API will expect each input sample to have 3 dimensions; \n",
    "so we need to expand the original numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of train images: 60000\n",
      "  Dimension of each picture: 28x28\n"
     ]
    }
   ],
   "source": [
    "raw_train = mnist.train_images()\n",
    "normalized_data = np.asarray(raw_train/255, dtype=np.float32)\n",
    "train_data = np.expand_dims(normalized_data, axis=3)\n",
    "train_label = mnist.train_labels()\n",
    "\n",
    "print(\"Total number of train images: {}\".format(train_data.shape[0]))\n",
    "print(\"  Dimension of each picture: {}x{}\".format(train_data.shape[1],\n",
    "                                                  train_data.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test images: 10000\n",
      "  Dimension of each picture: 28x28\n"
     ]
    }
   ],
   "source": [
    "raw_data = mnist.test_images()\n",
    "normalized_data = np.asarray(raw_data/255, dtype=np.float32)\n",
    "test_data = np.expand_dims(normalized_data, axis=3)\n",
    "test_label = mnist.test_labels()\n",
    "\n",
    "print(\"Total number of test images: {}\".format(test_data.shape[0]))\n",
    "print(\"  Dimension of each picture: {}x{}\".format(test_data.shape[1],\n",
    "                                                  test_data.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_data[1,:,:,0], 'gray')\n",
    "plt.title('Label: {}'.format(test_label[1]))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use VART\n",
    "Now we should be able to use VART API to do the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpu = overlay.runner\n",
    "\n",
    "inputTensors = dpu.get_input_tensors()\n",
    "outputTensors = dpu.get_output_tensors()\n",
    "\n",
    "shapeIn = tuple(inputTensors[0].dims)\n",
    "shapeOut = tuple(outputTensors[0].dims)\n",
    "outputSize = int(outputTensors[0].get_data_size() / shapeIn[0]) # here we have outputsize = 576, for it is mid-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a few buffers to store input and output data.\n",
    "They will be reused during multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = [np.empty(shapeOut, dtype=np.float32, order=\"C\")]\n",
    "input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "image = input_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also define a few functions to calculate softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_softmax(data):\n",
    "    result = np.exp(data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run DPU to make predictions\n",
    "\n",
    "We can now classify a couple of digit pictures. For each picture, \n",
    "the classification result (shown as 'Prediction') is displayed on top of \n",
    "the picture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting train output from DPU model,shape(60000,576)\n",
      "getting test output from DPU model,shape(10000,576)\n"
     ]
    }
   ],
   "source": [
    "total = train_data.shape[0]\n",
    "mid_predictions = np.empty((total,outputSize))\n",
    "print(\"getting train output from DPU model,shape(60000,576)\")\n",
    "# print(mid_predictions.shape)\n",
    "assert mid_predictions.shape ==(60000,576)\n",
    "for i in range(total):\n",
    "    image[0,...] = train_data[i]\n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "    temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "# Debug utils\n",
    "#     print(type(temp[0][0]))\n",
    "#     print(mid_predictions[[i]].shape)\n",
    "#     print(temp[0][0].shape)\n",
    "    mid_predictions[[i]]=temp\n",
    "assert mid_predictions.shape ==(60000,576)\n",
    "np.save(\"train_elm.npy\",mid_predictions)\n",
    "\n",
    "total = test_data.shape[0]\n",
    "mid_predictions = np.empty((total,outputSize))\n",
    "print(\"getting test output from DPU model,shape(10000,576)\")\n",
    "# print(mid_predictions.shape)\n",
    "assert mid_predictions.shape ==(10000,576)\n",
    "for i in range(total):\n",
    "    image[0,...] = train_data[i]\n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "    temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "#     print(type(temp[0][0]))\n",
    "#     print(mid_predictions[[i]].shape)\n",
    "#     print(temp[0][0].shape)\n",
    "    mid_predictions[[i]]=temp\n",
    "assert mid_predictions.shape ==(10000,576)\n",
    "np.save(\"test_elm.npy\",mid_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Basic ELM\n",
    "The following ELMRegressor is a simple ELM structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ELMRegressor():\n",
    "    def __init__(self, n_hidden_units,output_shape):\n",
    "        self.n_hidden_units = n_hidden_units\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def fit(self, X, labels):\n",
    "        X = np.column_stack([X, np.ones([X.shape[0], 1])])\n",
    "        self.random_weights = np.random.randn(X.shape[1], self.n_hidden_units)\n",
    "        G = np.tanh(X.dot(self.random_weights))\n",
    "        self.w_elm = np.linalg.pinv(G).dot(labels)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.column_stack([X, np.ones([X.shape[0], 1])])\n",
    "        G = np.tanh(X.dot(self.random_weights))\n",
    "        return G.dot(self.w_elm)\n",
    "\n",
    "# elm = ELMRegressor(n_hidden_units=100)\n",
    "# elm.fit(train_x, train_y)\n",
    "\n",
    "# prediction = elm.predict(test_x)\n",
    "\n",
    "# elm = ELMRegressor(n_hidden_units=500,output_shape=10)\n",
    "# elm.fit(train_x, train_y)\n",
    "# prediction = elm.predict(test_x)\n",
    "# prediction.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.IELM \n",
    "[Incremental-Extreme-Learning-Machine-IELM](https://github.com/ankitpatel21/Incremental-Extreme-Learning-Machine-IELM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class I_ELM():\n",
    "    \"\"\" Constructor to initialize node\"\"\"\n",
    "    def __init__(self, no_input_nodes, max_no_hidden_nodes, no_output_nodes,\n",
    "        activation_function='sigmoid', loss_function='mean_squared_error'):\n",
    "\n",
    "        #self.name = name\n",
    "        self.no_input_nodes = no_input_nodes\n",
    "        self.no_hidden_nodes = 1\n",
    "        self.no_output_nodes = no_output_nodes\n",
    "\n",
    "        # initialize weights between  hidden layer and Output Layer\n",
    "        self.beta = np.random.uniform(-1.,1.,size=(self.no_hidden_nodes, self.no_output_nodes))\n",
    "        # initialize weights between Input Layer and hidden layer\n",
    "        self.alpha = np.random.uniform(-1.,1.,size=(self.no_input_nodes, self.no_hidden_nodes))\n",
    "        #Initialize Biases\n",
    "        self.bias = np.zeros(shape=(self.no_hidden_nodes,))\n",
    "        # set an activation function\n",
    "        self.activation_function = activation_function\n",
    "        # set a loss function\n",
    "        self.loss_function = loss_function\n",
    "    \n",
    "    def mean_squared_error(self,Y_True, Y_Pred):\n",
    "        return 0.5 * np.mean((Y_True - Y_Pred)**2)\n",
    "\n",
    "    def mean_absolute_error(self, Y_True, Y_Pred):\n",
    "        return np.mean(np.abs(Y_True - Y_Pred))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return list(self(X))\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        h = self.sigmoid(X.dot(self.alpha) + self.bias)\n",
    "        return h.dot(self.beta)\n",
    "\n",
    "    def evaluate(self, X, Y_true, metrics=['loss']):\n",
    "        Y_pred = self.predict(X)\n",
    "        Y_true = Y_true\n",
    "        Y_pred_argmax = np.argmax(Y_pred, axis=-1)\n",
    "        Y_true_argmax = np.argmax(Y_true, axis=-1)\n",
    "        ret = []\n",
    "        for m in metrics:\n",
    "            if m == 'loss':\n",
    "                loss = self.mean_squared_error(Y_true, Y_pred)\n",
    "                ret.append(loss)\n",
    "            elif m == 'accuracy':\n",
    "                acc = np.sum(Y_pred_argmax == Y_true_argmax) / len(Y_true)\n",
    "                ret.append(acc)\n",
    "            else:\n",
    "                raise ValueError('an unknown evaluation indicator \\'%s\\'.' % m)\n",
    "        if len(ret) == 1:\n",
    "            ret = ret[0]\n",
    "        elif len(ret) == 0:\n",
    "            ret = None\n",
    "        return ret\n",
    "\n",
    "    def fit(self, X, Y_true,Lmax,error):\n",
    "        self.beta = np.random.uniform(-1.,1.,size=(1, self.no_output_nodes))\n",
    "        self.alpha = np.random.uniform(-1.,1.,size=(self.no_input_nodes, 1))\n",
    "#         print(self.beta.shape,self.alpha.shape)\n",
    "        H = self.sigmoid(X.dot(self.alpha))\n",
    "        # compute a pseudoinverse of H\n",
    "        H_pinv = np.linalg.pinv(H)\n",
    "        # update beta\n",
    "        self.beta = H_pinv.dot(Y_true)\n",
    "\n",
    "        \n",
    "        for i in range(2,Lmax):\n",
    "            beta_random = np.random.uniform(-1.,1.,size=(1, self.no_output_nodes))\n",
    "            alpha_random = np.random.uniform(-1.,1.,size=(self.no_input_nodes, 1))\n",
    "            self.alpha=np.hstack([self.alpha,alpha_random])\n",
    "#             print(self.beta.shape,beta_random.shape)\n",
    "            self.beta = np.vstack([self.beta,beta_random])\n",
    "            H = self.sigmoid(X.dot(self.alpha))\n",
    "            # compute a pseudoinverse of H\n",
    "            H_pinv = np.linalg.pinv(H)\n",
    "            # update beta\n",
    "            self.beta = H_pinv.dot(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 576)\n",
      "(60000, 1)\n",
      "(10000, 576)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# prepare train data\n",
    "train_x = np.load(\"train_elm.npy\")\n",
    "train_y = mnist.train_labels().reshape(train_x.shape[0],1)\n",
    "test_x = np.load(\"test_elm.npy\")\n",
    "test_y = mnist.test_labels().reshape(test_x.shape[0],1)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "def to_categorical(labels,num_classes): #label (numï¼Œ1)\n",
    "    if np.max(labels)>num_classes:\n",
    "        print(\"num label bigger than num classes\")\n",
    "    array = labels.squeeze(axis=1).tolist()\n",
    "    one_label = np.eye(num_classes)[array]\n",
    "    return one_label\n",
    "Y_Train = to_categorical(train_y, 10).astype(np.float32)\n",
    "print(Y_Train.shape)\n",
    "# check if label is unchanged\n",
    "for i in range(train_y.shape[0]):\n",
    "#     print(train_y[i,:][0])\n",
    "#     print(Y_Train[i,:][train_y[i,:][0]])\n",
    "    assert Y_Train[i,:][train_y[i,:][0]]==1.0\n",
    "print(\"labels all checked and there is no wrong label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "Lmax = 100 # this param should not be so big, fot it can be quite long to train\n",
    "error = 0.1\n",
    "loss_function = \"mean_squared_error\"  #It can be mean_absolute_error also\n",
    "\n",
    "def normalization(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    return (data - np.min(data)) / _range\n",
    "\n",
    "def standardization(data):\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.std(data, axis=0)\n",
    "    sigma[sigma==0]=1\n",
    "    return (data - mu) / sigma\n",
    "\n",
    "# Normalization\n",
    "# X_Train = normalization(train_x.astype(np.float32))# / 255.\n",
    "# X_Test = normalization(test_x.astype(np.float32))# / 255.\n",
    "\n",
    "#Standardization\n",
    "X_Train = standardization(train_x.astype(np.float32))\n",
    "X_Test = standardization(test_x.astype(np.float32))\n",
    "\n",
    "#divided by max value\n",
    "# X_Train=train_x.astype(np.float32)/np.max(train_x)\n",
    "# X_Test=test_x.astype(np.float32)/np.max(test_x)\n",
    "\n",
    "# make one hot label\n",
    "Y_Train = to_categorical(train_y, num_classes).astype(np.float32)\n",
    "Y_Test = to_categorical(test_y, num_classes).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-97798141f9d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-ad06e2add7a3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y_true, Lmax, error)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# compute a pseudoinverse of H\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mH_pinv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;31m# update beta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH_pinv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/pynq-venv/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   2008\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mlarge\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "activation_function = \"sigmoid\"\n",
    "model = I_ELM(\n",
    "        no_input_nodes=train_x.shape[1],\n",
    "        max_no_hidden_nodes=Lmax,\n",
    "        no_output_nodes=num_classes,\n",
    "        loss_function=loss_function,\n",
    "        activation_function=activation_function,  \n",
    "    )\n",
    "import time\n",
    "i = time.time()\n",
    "model.fit(X_Train, Y_Train,Lmax,error)\n",
    "final = time.time()\n",
    "training_loss, training_acc = model.evaluate(X_Train, Y_Train, metrics=['loss', 'accuracy'])\n",
    "print('Training Loss in mean square error: %f' % training_loss) # loss value\n",
    "print('Training Accuracy: %f' % training_acc)# accuracy\n",
    "print('Total Time require for Training %f Seconds'% (final-i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = time.time()\n",
    "test_loss, test_acc = model.evaluate(X_Test, Y_Test, metrics=['loss', 'accuracy'])\n",
    "final = time.time()\n",
    "print('Test Loss in mean square error: %f' % test_loss) # loss value\n",
    "print('Test Accuracy: %f' % test_acc)# accuracy\n",
    "print('Total Time require for Test %f Seconds'% (final-i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Result Analysis\n",
    "The reason I did not get expected accuracy result is that we have INT8 network at previous steps, and ELM is FP32.\n",
    "the following code is a sample of train_x of mid-output which was generated by DPU inferenced xmodel. Compared With original data, it is has more repeated values, which gives no valuable information. So there is no way that ELM can deal with it without some data processing.\n",
    "I have no idea at this moment, hope I can figure it out later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.96875, 2.34375, 3.46875, 3.96875, 0.     , 3.96875, 0.     ,\n",
       "       2.40625, 1.53125, 3.96875, 3.96875, 0.     , 0.     , 3.375  ,\n",
       "       0.     , 0.     , 3.96875, 3.96875, 3.40625, 0.     , 3.96875,\n",
       "       3.96875, 0.     , 0.     , 3.96875, 0.     , 0.     , 0.     ,\n",
       "       3.96875, 0.     , 0.     , 3.96875, 0.     , 0.     , 3.96875,\n",
       "       0.53125, 0.     , 3.96875, 0.     , 0.1875 , 3.96875, 0.     ,\n",
       "       0.     , 0.     , 3.96875, 0.0625 , 0.     , 0.     , 0.     ,\n",
       "       3.96875, 3.96875, 0.84375, 0.     , 0.     , 1.4375 , 3.96875,\n",
       "       3.96875, 3.96875, 3.96875, 3.5    , 3.96875, 3.96875, 3.96875,\n",
       "       3.96875, 0.     , 3.96875, 3.96875, 3.96875, 0.     , 2.09375,\n",
       "       0.     , 3.96875, 0.     , 3.96875, 3.96875, 0.28125, 3.96875,\n",
       "       3.96875, 1.46875, 0.     , 3.96875, 3.5    , 0.     , 0.     ,\n",
       "       1.3125 , 3.96875, 3.96875, 0.     , 0.     , 0.     , 0.     ,\n",
       "       0.     , 3.96875, 3.96875, 0.     , 0.     , 3.5    , 0.     ,\n",
       "       3.96875, 0.     , 0.     , 0.     , 0.     , 0.     , 3.96875,\n",
       "       3.96875, 3.5625 , 0.     , 0.     , 0.     , 0.     , 3.96875,\n",
       "       3.53125, 3.96875, 3.96875, 3.96875, 2.15625, 3.96875, 0.     ,\n",
       "       3.96875, 3.96875, 3.96875, 3.96875, 3.96875, 0.     , 0.     ,\n",
       "       3.96875, 3.96875, 1.53125, 3.96875, 2.90625, 3.96875, 0.     ,\n",
       "       0.     , 0.     , 1.375  , 0.     , 0.     , 3.96875, 1.875  ,\n",
       "       0.     , 3.96875, 3.96875, 0.     , 0.     , 3.96875, 0.     ,\n",
       "       0.     , 0.5    , 3.96875, 0.     , 3.96875, 0.     , 0.     ,\n",
       "       0.     , 0.     , 3.96875, 1.375  , 0.     , 0.     , 0.     ,\n",
       "       0.     , 3.96875, 3.96875, 0.     , 3.96875, 0.     , 0.     ,\n",
       "       3.96875, 3.96875, 0.     , 2.9375 , 1.25   , 0.     , 0.     ,\n",
       "       3.96875, 0.     , 3.5625 , 0.     , 3.96875, 3.96875, 3.96875,\n",
       "       1.625  , 3.96875, 3.96875, 3.96875, 3.96875, 3.96875, 0.     ,\n",
       "       3.96875, 3.96875, 0.     , 0.     , 3.40625, 3.96875, 3.96875,\n",
       "       3.96875, 0.     , 3.96875, 0.     , 0.     , 3.96875, 3.96875,\n",
       "       0.     , 3.96875, 3.96875, 3.96875, 3.96875, 0.     , 2.75   ,\n",
       "       3.96875, 0.     , 3.96875, 3.96875, 0.     , 0.     , 0.     ,\n",
       "       0.     , 3.96875, 0.     , 3.96875, 0.     , 0.     , 0.     ,\n",
       "       0.1875 , 0.     , 3.96875, 0.21875, 0.     , 3.96875, 0.     ,\n",
       "       3.96875, 0.     , 0.     , 0.     , 3.96875, 0.     , 3.96875,\n",
       "       0.     , 3.96875, 1.5625 , 3.96875, 0.     , 3.96875, 0.     ,\n",
       "       3.96875, 3.96875, 1.5    , 3.96875, 3.96875, 3.96875, 3.96875,\n",
       "       3.96875, 3.96875, 3.65625, 3.96875, 1.5625 , 3.96875, 3.96875,\n",
       "       3.96875, 0.     , 0.     , 0.     , 3.96875, 3.96875, 3.96875,\n",
       "       3.96875, 0.     , 3.96875, 0.     , 3.96875, 0.     , 0.     ,\n",
       "       3.96875, 0.     , 0.     , 3.96875, 3.96875, 0.     , 3.96875,\n",
       "       0.     , 0.     , 3.96875, 0.     , 3.96875, 3.96875, 3.96875,\n",
       "       0.     , 0.     , 0.     , 3.96875, 3.96875, 0.     , 3.96875,\n",
       "       0.     , 0.     , 3.96875, 3.96875, 3.96875, 3.96875, 0.     ,\n",
       "       0.     , 0.     , 3.96875, 3.96875, 0.     , 3.96875, 3.96875,\n",
       "       3.96875, 3.96875, 2.125  , 0.     , 3.96875, 0.     , 3.96875,\n",
       "       0.     , 3.65625, 3.96875, 3.96875, 0.     , 0.     , 0.     ,\n",
       "       3.96875, 3.96875, 0.     , 0.     , 0.     , 3.96875, 0.     ,\n",
       "       0.     , 3.96875, 0.     , 3.96875, 3.96875, 0.125  , 0.     ,\n",
       "       2.375  , 3.96875, 0.     , 0.     , 3.84375, 3.96875, 0.     ,\n",
       "       0.     , 0.     , 0.     , 0.     , 0.     , 3.96875, 3.96875,\n",
       "       0.     , 0.     , 0.     , 0.     , 3.96875, 3.96875, 0.     ,\n",
       "       3.96875, 0.     , 0.     , 0.     , 3.96875, 3.96875, 0.     ,\n",
       "       0.     , 0.     , 0.59375, 3.96875, 3.96875, 2.90625, 0.     ,\n",
       "       3.96875, 3.96875, 3.96875, 3.96875, 3.96875, 3.96875, 3.96875,\n",
       "       3.96875, 0.     , 0.     , 0.     , 3.96875, 3.96875, 0.65625,\n",
       "       3.96875, 3.96875, 3.96875, 0.     , 0.     , 3.96875, 3.96875,\n",
       "       0.     , 3.96875, 0.     , 3.53125, 3.96875, 0.     , 0.     ,\n",
       "       3.96875, 0.     , 3.96875, 3.96875, 0.     , 3.96875, 3.96875,\n",
       "       0.     , 0.     , 0.     , 0.     , 3.96875, 2.46875, 0.     ,\n",
       "       0.     , 0.     , 0.     , 0.     , 0.     , 3.96875, 2.375  ,\n",
       "       0.     , 3.96875, 0.     , 0.     , 3.96875, 0.     , 0.     ,\n",
       "       3.96875, 0.     , 0.     , 0.     , 3.96875, 3.6875 , 0.     ,\n",
       "       0.78125, 3.96875, 3.96875, 3.96875, 3.96875, 0.     , 3.96875,\n",
       "       3.96875, 3.96875, 3.1875 , 3.96875, 3.96875, 0.     , 0.     ,\n",
       "       0.     , 0.     , 3.96875, 3.96875, 3.96875, 0.     , 0.     ,\n",
       "       3.96875, 0.     , 0.     , 3.15625, 0.     , 3.96875, 0.     ,\n",
       "       0.     , 0.     , 0.     , 3.96875, 3.96875, 0.     , 3.96875,\n",
       "       3.96875, 3.96875, 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
       "       3.96875, 0.     , 0.     , 0.     , 0.     , 0.     , 3.96875,\n",
       "       3.96875, 0.     , 3.96875, 0.     , 0.     , 3.96875, 3.96875,\n",
       "       0.     , 3.96875, 0.     , 3.96875, 0.     , 3.96875, 2.6875 ,\n",
       "       0.     , 0.     , 3.96875, 3.96875, 3.96875, 3.96875, 3.96875,\n",
       "       3.96875, 3.96875, 3.96875, 0.     , 3.96875, 1.5    , 0.     ,\n",
       "       0.     , 0.90625, 3.96875, 3.96875, 3.96875, 3.96875, 0.     ,\n",
       "       1.625  , 0.     , 0.     , 3.96875, 3.59375, 0.     , 0.     ,\n",
       "       0.     , 3.96875, 3.96875, 0.     , 3.96875, 0.     , 0.     ,\n",
       "       0.     , 3.96875, 0.     , 0.     , 0.     , 0.     , 0.     ,\n",
       "       0.     , 3.96875, 0.     , 2.90625, 0.     , 0.     , 0.     ,\n",
       "       0.     , 0.     , 0.     , 3.96875, 0.     , 0.     , 0.     ,\n",
       "       0.875  , 0.53125, 0.     , 0.     , 0.     , 0.     , 3.96875,\n",
       "       0.     , 0.     , 3.96875, 3.96875, 0.     , 3.96875, 3.96875,\n",
       "       0.     , 0.     , 3.96875, 3.96875, 3.96875, 0.     , 3.96875,\n",
       "       3.96875, 0.     ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clean up\n",
    "\n",
    "We will need to remove references to `vart.Runner` and let Python garbage-collect\n",
    "the unused graph objects. This will make sure we can run other notebooks without\n",
    "any issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dpu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-92d73612220e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0moverlay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dpu' is not defined"
     ]
    }
   ],
   "source": [
    "del overlay\n",
    "del dpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Copyright (C) 2021 Xilinx, Inc\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0 License\n",
    "\n",
    "----\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
